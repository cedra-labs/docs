---
title: Quick Start
sidebar_position: 3
---

# üõ†Ô∏è SDK Guide

Get a working indexer in 5 minutes using our example repository. This guide shows you how to index ALL events from Cedra blockchain into PostgreSQL, then query them via GraphQL.

## Prerequisites

<details>
<summary>**üìã Required Tools** - Click to expand installation commands</summary>

### **Rust & Cargo** (1.78+)
```bash
# Install Rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env

# Verify
cargo --version
```

### **PostgreSQL** (14+)
```bash
# macOS
brew install postgresql
brew services start postgresql

# Ubuntu/Debian
sudo apt install postgresql postgresql-contrib
sudo systemctl start postgresql

# Verify
psql --version
```

### **Diesel CLI**
```bash
cargo install diesel_cli --no-default-features --features postgres
```

</details>

## Understanding the Structure

üìÇ **[Cedra Indexer SDK Examples Repository](https://github.com/cedra-labs/cedra-indexer-processor-sdk/tree/main/examples)**

Navigate to `examples/postgres-basic-events-example` - this is your starting point.
The example provides a complete indexer. Here's what each file does:

### **üìÑ `src/main.rs`** - The Heart of Your Indexer
[View on GitHub](https://github.com/cedra-labs/cedra-indexer-processor-sdk/blob/main/examples/postgres-basic-events-example/src/main.rs)

This file contains the magic - a simple `process` function that handles everything:

```rust
process(
    "events_processor",        // Your processor name
    MIGRATIONS,                // Auto-runs database migrations
    async |transactions, db| { // Your processing logic
        // Extract events from transactions
        // Store them in PostgreSQL
        // That's it!
    }
)
```

**Why use it:** The `process` function abstracts away all complexity - connection management, error handling, progress tracking, and recovery. You just focus on what data to extract.

### **üìÑ `src/events_model.rs`** - Event Data Structure
[View on GitHub](https://github.com/cedra-labs/cedra-indexer-processor-sdk/blob/main/examples/postgres-basic-events-example/src/events_model.rs)

Defines how events are structured and stored:

```rust
pub struct Event {
    pub account_address: String,     // Who emitted the event
    pub type_: String,               // Event type (e.g., "0x1::coin::TransferEvent")
    pub data: serde_json::Value,    // Event payload as JSON
    pub transaction_version: i64,    // When it happened
    // ... more fields
}
```

**Why use it:** This model captures ALL essential event data. It's generic enough to handle any event type while maintaining queryability through PostgreSQL's JSONB support.

### **üìÑ `src/db/schema.rs`** - Database Schema
[View on GitHub](https://github.com/cedra-labs/cedra-indexer-processor-sdk/blob/main/examples/postgres-basic-events-example/src/db/schema.rs)

Auto-generated by Diesel, defines your database structure:

```rust
diesel::table! {
    events (transaction_version, event_index) {
        account_address -> Varchar,
        type_ -> Text,
        data -> Jsonb,  // Flexible JSON storage
        // ... more columns
    }
}
```

**Why use it:** The schema is optimized with:
- Composite primary key for uniqueness
- JSONB for flexible event data
- Indexes on commonly queried fields

### **üìÑ `example-config.yaml`** - Configuration Template
[View on GitHub](https://github.com/cedra-labs/cedra-indexer-processor-sdk/blob/main/examples/postgres-basic-events-example/example-config.yaml)

Simple configuration that connects everything (GRPC in example):

```yaml
server_config:
  transaction_stream_config:
    indexer_grpc_data_service_address: GRPC_ADDRESS
    starting_version: 0  # Start from genesis
  postgres_config:
    connection_string: PG_CONNECTION_STRING
```

**Why use it:** Zero authentication needed! Just point to indexer grpc address and PostgreSQL to go.

### **üìÑ `Cargo.toml`** - Dependencies
[View on GitHub](https://github.com/cedra-labs/cedra-indexer-processor-sdk/blob/main/examples/postgres-basic-events-example/Cargo.toml)

Pre-configured with all necessary dependencies:
- `cedra-indexer-processor-sdk` - The SDK that does the heavy lifting
- `diesel` - Database ORM for PostgreSQL
- `tokio` - Async runtime
- `rayon` - Parallel processing for performance

## Set Up Database

Now let's create and prepare your PostgreSQL database for the indexer:

```bash
# Create a new database specifically for your indexer
createdb cedra_indexer
```

This creates a fresh PostgreSQL database named `cedra_indexer`. You can verify it exists:

```bash
# List all databases
psql -l | grep cedra_indexer
```

Next, set the database URL environment variable that Diesel uses for migrations:

```bash
# Tell Diesel where your database is
export DATABASE_URL=postgresql://localhost/cedra_indexer
```

The example includes pre-written migrations in `src/db/migrations` that will create the necessary tables. Run them:

```bash
# Navigate to the database directory
cd src/db

# Run all migrations to create tables
diesel migration run

# Go back to project root
cd ../..
```

After running migrations, your database will have three essential tables:
- **`events`** - Stores all blockchain events with their data
- **`processor_status`** - Tracks your indexer's progress (last processed version)
- **`ledger_infos`** - Stores blockchain metadata

You can verify the tables were created:

```bash
# Connect to database and list tables
psql cedra_indexer -c "\dt"
```

:::tip Database GUI
To easily explore your indexed data later, consider installing [DBeaver](https://dbeaver.io/) or [pgAdmin](https://www.pgadmin.org/). Connect using: `postgresql://localhost/cedra_indexer`
:::

## Configure & Run

First, create your configuration file from the template:

```bash
# Copy the example configuration
cp example-config.yaml config.yaml
```

Now edit `config.yaml` to point to your database. Open it in your editor and change:

```yaml
# FROM this (example default):
postgres_config:
  connection_string: postgresql://postgres:@localhost:5432/example

# TO this (your actual database):
postgres_config:
  connection_string: postgresql://localhost:5432/cedra_indexer
```

The configuration tells your indexer:
- **Where to get data**: `indexer_grpc_data_service_address` points to grpc service
- **Where to start**: `starting_version: 0` means begin from genesis (first block)
- **Where to store**: `connection_string` points to your PostgreSQL database

Build your indexer in release mode (optimized for speed):

```bash
# Compile with optimizations
cargo build --release
```

This might take a few minutes the first time as it downloads and compiles dependencies.

Finally, run your indexer:

```bash
# Start indexing! The -- separates cargo args from your program args
cargo run --release -- -c config.yaml
```


## üí° Customizing the Example

### Filter Specific Events
Edit `src/main.rs` to index only what you need:

```rust
// Only process your contract's events
let filtered_events: Vec<_> = raw_events
    .iter()
    .filter(|e| e.type_str.contains("0xYOUR_ADDRESS::your_module"))
    .cloned()
    .collect();
```

### Add Custom Processing
Transform data before storing:

```rust
// Extract specific fields from event data
for event in &mut events {
    if let Some(amount) = event.data.get("amount") {
        // Process amount, calculate metrics, etc.
        info!("Processing amount: {}", amount);
    }
}
```

### Start From Specific Version
Don't need historical data? Start from recent blocks:

```yaml
transaction_stream_config:
  starting_version: 5000000  # Start from block 5M
```

## Next Steps

Your indexer is running! Here's what to explore next:

### üìö **Learn More**
- **[How Indexing Works](/indexer/how-it-works)** - Understand the complete data pipeline
- **[Architecture Guide](/indexer/architecture)** - How the SDK works internally
- **[Common Queries](/indexer/common-queries)** - GraphQL query patterns
- **[Custom Processors](/indexer/custom-processors)** - Build specialized indexers